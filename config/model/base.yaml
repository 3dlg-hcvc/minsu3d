# Managed by Hydra

ckpt_path: null


log:
  module: WandbLogger  # WandbLogger or TensorBoardLogger
  # https://pytorch-lightning.readthedocs.io/en/stable/extensions/generated/pytorch_lightning.loggers.WandbLogger.html
  WandbLogger:
    project: General
    name: run_1
  # https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.loggers.tensorboard.html
  TensorBoardLogger:
    name: General
    default_hp_metric: False


# https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html
trainer:
  accelerator: gpu
  devices: auto
  strategy: ddp
  num_nodes: 1
  max_epochs: 496
  num_sanity_val_steps: 20
  check_val_every_n_epoch: 8


# https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.callbacks.ModelCheckpoint.html
checkpoint_monitor:
  monitor: null
  mode: max
  save_last: False
  save_top_k: -1
  every_n_epochs: 8


# https://pytorch-lightning.readthedocs.io/en/stable/common/optimization.html
optimizer:
    name: Adam # Adam, AdamW or SGD
    lr: 0.0015


lr_decay:
  decay_start_epoch: 128
  decay_stop_epoch: 496


inference:
  split: val
  evaluate: True
  save_predictions: False
  output_dir: prediction
